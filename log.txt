C:\xampp\htdocs\exp\expNJDataSetFullSet.php
http:\\localhost\exp\expNJDataSetFullSet.php

until 3.3.19
============
reached overfitting
Jitter did not change the outcome
ViewModel.py - show layer 1, and first 64 conv of 2nd layer as images
ViewActivationLayers.py - draw all activation layers (image*layer) as images (layer_?.png)
SaliencyMap.py - create Saliency Map for 3 images

4.3.19
======
3 models:
!pip install numpy==1.16.2
!pip install Pillow==5.4.1
!pip install -q https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl
!pip install torchvision==0.2.2.post3
Training on stage 6
Train all layers (param.requires_grad = True)
lr=0.00004
3 epocs
no scheduler
activation maps (taken from cnn-visualizations)
===============================================
on s1-s3 stage8.4-8.6 (different for disperesed)
loads model and s1-s3 images in misc_functions.py\get_example_params
gradcam.py - Cam_Grayscale (Gradient-weighted Class Activation Map) Cam_Heatmap (Gradient-weighted Class Activation Heatmap)) Cam_On_Image (Gradient-weighted Class Activation Heatmap on Image). gradient of 11's layer (last conv later) multiplied by the output of that layer (13x13 image) resized to input image (224,224)
guided_backprop.py - Guided_BP_color (Colored Guided Backpropagation) Guided_BP_gray (Guided Backpropagation Saliency) neg_sal (Guided Backpropagation Negative Saliency) pos_sal(Guided Backpropagation Positive Saliency). Take gradient of last BP layer. Guided means only positive gradient where activation function (ReLU) result is larger than 0.
guided_gradcam.py - GGrad_Cam (Colored Guided Gradient-weighted Class Activation Map) GGrad_Cam_gray(Guided Gradient-weighted Class Activation Map Saliency)

GeneralizationFullAlexNet6:
===========================
1 most 0 least
alexnetModelSingle6.pt
DataSet-ordered-most
train Loss: 0.0042 Acc: 0.9991
Stage8.1 - Loss: 0.0000 Acc: 1.0000
Stage8.2 - Loss: 0.0000 Acc: 1.0000
Stage8.3 - Loss: 0.0043 Acc: 0.9987
Stage8.4 - Loss: 0.0093 Acc: 0.9987
Stage8.5 - Loss: 0.5443 Acc: 0.8731
Stage8.6 - Loss: 0.5045 Acc: 0.8756
activation maps in results0
test with RunModelAlexNet6
most rule

GeneralizationFullAlexNet6Switch01:
===================================
0 most 1 least
alexnetModelSingleSwitch016.pt
DataSet-ordered-least
train Loss: 0.0105 Acc: 0.9972
Stage8.1 - Loss: 0.0000 Acc: 1.0000
Stage8.2 - Loss: 0.0000 Acc: 1.0000
Stage8.3 - Loss: 0.0051 Acc: 0.9974
Stage8.4 - Loss: 0.0113 Acc: 0.9962
Stage8.5 - Loss: 0.2886 Acc: 0.9026
Stage8.6 - Loss: 0.2997 Acc: 0.9000
activation maps in resultsSwitch
test with RunModelAlexNet6
most rule

GeneralizationFullAlexNet6dispersed:
====================================
balls dispersed
1 most 0 least
alexnetModelSingleDispersed6.pt
DataSet
train Loss: 0.0166 Acc: 0.9983
Stage8.1 - Loss: 0.0066 Acc: 0.9985
Stage8.2 - Loss: 0.0000 Acc: 1.0000
Stage8.3 - Loss: 0.0559 Acc: 0.9938
Stage8.4 - Loss: 0.7958 Acc: 0.9141
Stage8.5 - Loss: 1.0259 Acc: 0.9257
Stage8.6 - Loss: 0.5111 Acc: 0.9579
activation maps in resultsDispersed
test with RunModelAlexNet6dispersed
most rule

6.3.2019
========
vis.py - visualize the input data (regular and dispersed) in a single large image with thumbnail input images at the coordinates of:
1. model output class probability - vis[-dispersed].png
2. model classifier 2nd fc layer (4) 4096 features -> t-sne 2 featurs - t-sne[-label][-dispersed].png
images are under dataset/vis taken from 8.4/1 and 8.5/0

7.3.2019
========
On average 86% out of the 4096 features neurons of the 4th layer are 0 for all 500 images in vis
Meeting with Lea and Yonatan:
ordered balls (Jhon and Lea) 80% least rule 20% most 0% Majority
Dispersed balls (Lea): 63% Most 7% least 8.5% Majority 13% Majority+Most 8.5% non-consistent
Get numbers:
1. reaction time in 6th stage Dispersed vs. Ordered, Most vs. least
2. trial numbers in 1st and 2nd stage most vs. least
DB: https://my.webfaction.com login: tsirkinlea Pass: Lab25364964 -> DataBases -> circlesdb -> phpMyAdmin
login: tsirkinlea Pass: 25364964
all 2018 (some users get opp buttons)
first ~117 pages has no stage

SELECT id,count(*) FROM `2colorsRingDecOpp_2018` where `date`>'2019-01-22' and stage=1 GROUP BY `id`
UNION
SELECT id,count(*) FROM `2colorsRingDec_2018` where `date`>'2019-01-22' and stage=1 GROUP BY `id`

SELECT id,avg(time) FROM `3colorsRingDecOpp_2018` where `date`>'2019-01-22' and (stage=5 or stage=6) group by id

12.3.2019
=========
retrain DataSet-collected-most and DataSet (dispersed)
used GeneralizationAlexNet.ipynb to train and RunModelAlexNet to test
ordered models save in ordered models (in Gdrive under Colab Notebooks)

ordered
learningRates = [0.00004,0.00004,0.0001,0.0001,0.0001,0.00004]
stepSize = [40,40,40,40,40,40]
gammaStage = [0.5,0.5,0.5,0.5,0.5,0.5]
epochs = [10,100,100,15,10,5]

	    2	3	    4	    5	    6
2	    1	1	    0.7	    0.75	0.6
3	    0.6	1	    0.6	    0.75	0.5
4	    0.6	0.65	1	    1   	0.65
5	    0.5	0.5	    0.9	    1	    0.57
6	    0.5	0.5	    0.86	1	    1
8.1	    1	1	    0.4	    1   	1
8.2	    0	0	    1   	1   	1
8.3	    0	0	    1	    1	    1
8.4	    1	1	    0	    0.75	1
8.5	    0	0	    1	    1	    1
8.6	    0	0	    1	    1	    1
Rule*	S?	S?   	?	    L	    L

*8.1-8.6 are set for largest rule so acc 1 means largest  (class 1,0,0,1,0,0 left,right,right,left,right,right)

Dispersed
learningRates = [0.00004,0.00004,0.0001,0.0001,0.0001,0.00004]
stepSize = [40,40,40,40,40,40]
gammaStage = [0.5,0.5,0.5,0.5,0.5,0.5]
epochs = [10,5,80,7,12,5]

	    2	    3	    4	    5	    6
2	    1	    1	    0.7	    0.75	0.6
3	    0.56    1	    0.6	    0.75	0.5
4	    0.55    0.65	1	    1   	0.65
5	    0.5	    0.5	    0.9	    1	    0.57
6	    0.5	    0.5	    0.86	1	    1
8.1	    0.96	1	    0.4	    1   	1
8.2	    0.2	    0	    1   	1   	1
8.3	    0.2	    0	    1	    1	    1
8.4	    0.92    0.65    0	    0.67	0.92
8.5	    0.14    0.5	    1	    1	    1
8.6	    0.1	    0.4	    1	    1	    1
Rule*	S?	    ?      	?	    L	    L

fixed mean and std
mean_ordered = [[0.14698932, 0.07864558, 0.07864558],
        [0.1470285, 0.07893109, 0.07893109],
        [0.10425095, 0.09806027, 0.06648784],
        [0.16401494, 0.15427534, 0.10460336],
        [0.17739601, 0.16686181, 0.11313736],
        [0.18770611, 0.17655967, 0.11971281],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741],
        [0.19887728, 0.18706746, 0.12683741]]
std_ordered = [[0.33980202, 0.26861356, 0.26861356],
        [0.33989204, 0.26905882, 0.26905882],
        [0.27920483, 0.26909579, 0.22966473],
        [0.33592059, 0.32442553, 0.28106323],
        [0.34594089, 0.33427331, 0.2906474],
        [0.35312213, 0.34135106, 0.29765486],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059],
        [0.36040904, 0.34855344, 0.3049059]]
mean_dispersed = [[0.1485085, 0.07972562, 0.07972562],
        [0.1485085, 0.07972562, 0.07972562],
        [0.10530034,0.09904735, 0.06715711],
        [0.1723193, 0.16208656, 0.1098996 ],
        [0.19028167,0.1793008,  0.12116231],
        [0.18749268,0.17634825, 0.11966386],
        [0.19885103,0.18705591, 0.12685093],
        [0.19885103,0.18705591, 0.12685093],
        [0.19885103,0.18705591, 0.12685093],
        [0.19885103,0.18705591, 0.12685093],
        [0.19885103,0.18705591, 0.12685093],
        [0.19885103,0.18705591, 0.12685093]]
std_dispersed = [[0.34127658, 0.27029246, 0.27029246],
       [0.34127658, 0.27029246, 0.27029246],
       [0.28040959, 0.27026595, 0.23072036],
       [0.34223538, 0.33062806, 0.28707876],
       [0.35507738, 0.34346676, 0.29920025],
       [0.35292448, 0.34116759, 0.29759443],
       [0.36037928, 0.34853642, 0.30491646],
       [0.36037928, 0.34853642, 0.30491646],
       [0.36037928, 0.34853642, 0.30491646],
       [0.36037928, 0.34853642, 0.30491646],
       [0.36037928, 0.34853642, 0.30491646],
       [0.36037928, 0.34853642, 0.30491646]]

13.3.2019
=========
guided_gradcam2.py - display salient and grad cam heatmaps on specific images
